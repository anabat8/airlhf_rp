{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:08.702687Z",
     "start_time": "2024-06-10T17:26:02.404092Z"
    }
   },
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import torch \n",
    "import random\n",
    "\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from experiment3.RLHFAgent import RLHFAgent\n",
    "from experiment3.AIRLAgent import AIRLAgent\n",
    "from experiment3.Utils import Utils\n",
    "from experiment3.Environment import Environment"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:11.552313Z",
     "start_time": "2024-06-10T17:26:11.503249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize environment\n",
    "SEED = 42\n",
    "env = Environment(\"seals:seals/CartPole-v0\", SEED, num_envs=8)\n",
    "env.init_vec_env()"
   ],
   "id": "dffee0d2ba446207",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ana\\PycharmProjects\\research_project\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:233: UserWarning: Starting from gymnasium v0.26, render modes are determined during the initialization of the environment.\n",
      "                We allow to pass a mode argument to maintain a backwards compatible VecEnv API, but the mode (rgb_array)\n",
      "                has to be the same as the environment render mode (None) which is not the case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv at 0x20bba622320>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:13.733278Z",
     "start_time": "2024-06-10T17:26:13.717303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_rlhf(num_comparisons, exploration_frac=0.05, fragment_length=100):\n",
    "    # Initialize RLHFAgent\n",
    "    rlhfAgent = RLHFAgent(env_object=env)\n",
    "    rlhfAgent.init_gen_algo(policy_name=\"PPO\", ac_policy=MlpPolicy, env_object=env)\n",
    "    rlhfAgent.init_trajectory_gen(env_object=env, exploration_frac=exploration_frac)\n",
    "    \n",
    "    # Train RLHFAgent alone\n",
    "    rlhfAgent.train(save_path=pathlib.Path(\"rlhf_agent\"), env_object=env, total_human_comparisons=num_comparisons, total_timesteps=400_000,\n",
    "                    fragment_length=fragment_length)\n"
   ],
   "id": "373ad432019d8ff1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:14.563870Z",
     "start_time": "2024-06-10T17:26:14.548247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_airl():\n",
    "    # Initialize AIRLAgent\n",
    "    airlAgent = AIRLAgent(env_object=env)\n",
    "    airlAgent.init_gen_algo(ac_policy=MlpPolicy, env_object=env)\n",
    "    \n",
    "    # Train AIRLAgent alone\n",
    "    # Train for >400k for 100% learned rewards, 280k for 70% learned rewards, 200k for 50% learned rewards, 80k for 20% learned rewards, 20k for 5% learned rewards\n",
    "    airlAgent.train(env_object=env, train_steps=20_000)"
   ],
   "id": "ee34b7d661c87f12",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:15.389388Z",
     "start_time": "2024-06-10T17:26:15.374879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_irlhf(reward_net_airl, num_comparisons, exploration_frac=0.05, fragment_length=100, num_it=60, initial_epoch_multiplier=4):\n",
    "    # Initialize RLHFAgent\n",
    "    rlhfAgent = RLHFAgent(env_object=env)\n",
    "    rlhfAgent.set_reward_from_airl(reward_net_airl, env_object=env)\n",
    "    rlhfAgent.init_gen_algo(policy_name=\"PPO\", ac_policy=MlpPolicy, env_object=env)\n",
    "    rlhfAgent.init_trajectory_gen(env_object=env, exploration_frac=exploration_frac)\n",
    "    \n",
    "    # Train RLHFAgent with reward initialized by AIRL\n",
    "    rlhfAgent.train(save_path=pathlib.Path(\"irlhf_agent\"), env_object=env, total_human_comparisons=num_comparisons, total_timesteps=400_000,\n",
    "                    fragment_length=fragment_length, num_it=num_it, initial_epoch_multiplier=initial_epoch_multiplier)\n",
    "    "
   ],
   "id": "425bfdb0a84a8496",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:16.243530Z",
     "start_time": "2024-06-10T17:26:16.212258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_reward_stats(path):\n",
    "    rewards = torch.load(path)\n",
    "    return rewards, np.mean(rewards), np.std(rewards)"
   ],
   "id": "c0ba932aa6bc8650",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:27.208685Z",
     "start_time": "2024-06-10T17:26:27.177052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from imitation.util.networks import RunningNorm\n",
    "from imitation.policies.base import NormalizeFeaturesExtractor\n",
    "\n",
    "\n",
    "def train_with_learned_reward_and_evaluate(reward_path, train_path, tensorboard_dir, tb_log_name, \n",
    "                                           wandb_project_name, wandb_save_path,\n",
    "                                           batch_size=64, lr=0.001, gamma=0.98, clip_range=0.2, n_epochs=20\n",
    "                                           ):\n",
    "    reward_net = torch.load(reward_path)\n",
    "    Utils.train_with_learned_reward(learned_reward=reward_net, save_path=train_path,  \n",
    "                                    ac_policy=MlpPolicy, tensorboard_dir=tensorboard_dir, tb_log_name=tb_log_name, \n",
    "                                    env_object=env, wandb_project_name=wandb_project_name, wandb_save_path=wandb_save_path,\n",
    "                                    batch_size=batch_size, lr=lr, gamma=gamma, clip_range=clip_range, n_epochs=n_epochs,\n",
    "                                    policy_kwargs=dict(\n",
    "                                        features_extractor_class=NormalizeFeaturesExtractor,\n",
    "                                        features_extractor_kwargs=dict(normalize_class=RunningNorm),\n",
    "                                    ))\n",
    "    eval_mean, eval_std = Utils.evaluate_trained_agent_with_learned_reward(load_path=train_path, venv=env.venv)\n",
    "    return eval_mean, eval_std"
   ],
   "id": "e98e428e75e819b2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:29.278998Z",
     "start_time": "2024-06-10T17:26:29.247751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # wrap env in new seed\n",
    "    env.seed = seed \n",
    "    env.rng = np.random.default_rng(seed)\n",
    "    env.init_vec_env()\n",
    "    env.venv.seed(seed)"
   ],
   "id": "21d3cd0b107948f6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training with different seeds and different demonstrations AIRL agent",
   "id": "798719038ed967c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:32.071528Z",
     "start_time": "2024-06-10T17:26:32.040279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main_train_airl():\n",
    "    rewards_over_seeds = [] \n",
    "    seed_list = [79]\n",
    "    # expert_demonstrations = []\n",
    "    \n",
    "    for i, seed in enumerate(seed_list): \n",
    "        # set seed\n",
    "        set_seed(seed)\n",
    "        \n",
    "        # start airl\n",
    "        means = []\n",
    "        stds = []\n",
    "        eval_policy_mean = []\n",
    "        eval_policy_std = []\n",
    "        \n",
    "        # Train\n",
    "        train_airl()\n",
    "        \n",
    "        rws, mean, std = get_reward_stats(\"./airl_agent/learner_rewards.pt\")\n",
    "            \n",
    "        means.append(mean)\n",
    "        stds.append(std)\n",
    "                    \n",
    "        eval_mean, eval_std = train_with_learned_reward_and_evaluate(\"airl_agent/reward_net.pt\", \"airl_agent/airl_agent_trained_with_learned_reward\",  \"./airl_cartpole_tensorboard\", f\"run_3_expert_with_{seed}\", \n",
    "         batch_size=64, lr=0.0005, gamma=0.95, clip_range=0.1, n_epochs=5,\n",
    "         wandb_project_name=\"airl\", wandb_save_path=f\"models/run_3_expert_with_{seed}\",)\n",
    "                \n",
    "        eval_policy_mean.append(eval_mean)\n",
    "        eval_policy_std.append(eval_std)\n",
    "            \n",
    "        # print(f\"number of expert demonstrations = {expert_dem}: mean={mean}, std={std}\")\n",
    "        # print(f\"number of expert demonstrations = {expert_dem}: eval_mean={eval_mean}, eval_std={eval_std}\")\n",
    "            \n",
    "        rewards_over_seeds.append(eval_policy_mean)"
   ],
   "id": "dc5a0590fd46a627",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "main_train_airl()",
   "id": "7d28b9f159d921ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training with different seeds and different nr of queries RLHF / IRLHF",
   "id": "56e77d98f7327ce8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:26:58.498913Z",
     "start_time": "2024-06-10T17:26:58.467668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main_train(agent_name, path):\n",
    "    rewards_over_seeds = [] # [0]: lists of means for seed 0, num comp 250,500,600 respectively\n",
    "    seed_list = [25, 34, 43, 52, 61, 70, 79]\n",
    "    comparisons_list = [10]\n",
    "    \n",
    "    for i, seed in enumerate(seed_list): \n",
    "        # set seed\n",
    "        set_seed(seed)\n",
    "        \n",
    "        # start rlhf / irlhf \n",
    "        means = []\n",
    "        stds = []\n",
    "        eval_policy_mean = []\n",
    "        eval_policy_std = []\n",
    "    \n",
    "        for idx, num_comparisons in enumerate(comparisons_list):\n",
    "            if agent_name == \"rlhf\":\n",
    "                train_rlhf(num_comparisons)\n",
    "            if agent_name == \"irlhf\":\n",
    "                # Train airl under current seed\n",
    "                train_airl()\n",
    "                # Load trained AIRLAgent reward function\n",
    "                reward_net_airl = torch.load(\"airl_agent/reward_net.pt\")\n",
    "                # Pass initialized reward function (can be 100%, 70%, 50%, 20%, 5%) to irlhf\n",
    "                # Train irlhf (optimize reward function)\n",
    "                if num_comparisons == 10:\n",
    "                    train_irlhf(reward_net_airl, num_comparisons, exploration_frac=0.05, fragment_length=100, num_it=8, initial_epoch_multiplier=4)\n",
    "                else:\n",
    "                    train_irlhf(reward_net_airl, num_comparisons, exploration_frac=0.05, fragment_length=100, num_it=60, initial_epoch_multiplier=4)\n",
    "                \n",
    "            rws, mean, std = get_reward_stats(path)\n",
    "            \n",
    "            means.append(mean)\n",
    "            stds.append(std)\n",
    "            \n",
    "            eval_mean = None\n",
    "            eval_std = None\n",
    "            \n",
    "            # Train agent using the learned reward, optimize policy\n",
    "            \n",
    "            if agent_name == \"rlhf\":\n",
    "                eval_mean, eval_std = train_with_learned_reward_and_evaluate(\n",
    "                    reward_path=\"rlhf_agent/reward_net.pt\",\n",
    "                    train_path=\"rlhf_agent/rlhf_agent_trained_with_learned_reward\",\n",
    "                    tensorboard_dir=\"./ppo_rlhf_cartpole_tensorboard/\",\n",
    "                    tb_log_name=f\"run5_comparisons_{num_comparisons}_with_seed_{seed}\",\n",
    "                    wandb_project_name=\"rlhf\",\n",
    "                    wandb_save_path=f\"models/run_comparisons_{num_comparisons}_with_seed_{seed}\"\n",
    "                )\n",
    "            if agent_name == \"irlhf\":\n",
    "                eval_mean, eval_std = train_with_learned_reward_and_evaluate(\n",
    "                    reward_path=\"irlhf_agent/reward_net.pt\",\n",
    "                    train_path=\"irlhf_agent/irlhf_agent_trained_with_learned_reward\",\n",
    "                    tensorboard_dir=\"./ppo_irlhf_cartpole_tensorboard/\",\n",
    "                    tb_log_name=f\"run8_comparisons_{num_comparisons}_with_seed_{seed}_irlhf_5%AIRLexpert\",\n",
    "                    wandb_project_name=\"irlhf\",\n",
    "                    wandb_save_path=f\"models/run_comparisons_{num_comparisons}_with_seed_{seed}_irlhf\"\n",
    "                )\n",
    "                \n",
    "            eval_policy_mean.append(eval_mean)\n",
    "            eval_policy_std.append(eval_std)\n",
    "            \n",
    "            print(f\"number of comparisons = {num_comparisons}: mean={mean}, std={std}\")\n",
    "            print(f\"number of comparisons = {num_comparisons}: eval_mean={eval_mean}, eval_std={eval_std}\")\n",
    "            \n",
    "        rewards_over_seeds.append(eval_policy_mean)"
   ],
   "id": "ef1029fef7a06040",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-10T17:27:01.709413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main_train(\"rlhf\", \"./rlhf_agent/learner_rewards.pt\")\n",
    "main_train(\"irlhf\", \"./irlhf_agent/learner_rewards.pt\")"
   ],
   "id": "8badcedc2672e530",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert stats:  {'n_traj': 64, 'return_min': 500.0, 'return_mean': 500.0, 'return_std': 0.0, 'return_max': 500.0, 'len_min': 500, 'len_mean': 500.0, 'len_std': 0.0, 'len_max': 500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| raw/                        |          |\n",
      "|    gen/rollout/ep_len_mean  | 500      |\n",
      "|    gen/rollout/ep_rew_mean  | 32.6     |\n",
      "|    gen/time/fps             | 2653     |\n",
      "|    gen/time/iterations      | 1        |\n",
      "|    gen/time/time_elapsed    | 6        |\n",
      "|    gen/time/total_timesteps | 16384    |\n",
      "------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.509    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0176   |\n",
      "|    disc/disc_entropy                | 0.635    |\n",
      "|    disc/disc_loss                   | 0.76     |\n",
      "|    disc/disc_proportion_expert_pred | 0.991    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.507    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0132   |\n",
      "|    disc/disc_entropy                | 0.637    |\n",
      "|    disc/disc_loss                   | 0.757    |\n",
      "|    disc/disc_proportion_expert_pred | 0.993    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.509    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0186   |\n",
      "|    disc/disc_entropy                | 0.639    |\n",
      "|    disc/disc_loss                   | 0.752    |\n",
      "|    disc/disc_proportion_expert_pred | 0.991    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.515    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0293   |\n",
      "|    disc/disc_entropy                | 0.642    |\n",
      "|    disc/disc_loss                   | 0.743    |\n",
      "|    disc/disc_proportion_expert_pred | 0.985    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.51     |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.02     |\n",
      "|    disc/disc_entropy                | 0.642    |\n",
      "|    disc/disc_loss                   | 0.746    |\n",
      "|    disc/disc_proportion_expert_pred | 0.99     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.514    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0283   |\n",
      "|    disc/disc_entropy                | 0.645    |\n",
      "|    disc/disc_loss                   | 0.737    |\n",
      "|    disc/disc_proportion_expert_pred | 0.986    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.517    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0332   |\n",
      "|    disc/disc_entropy                | 0.646    |\n",
      "|    disc/disc_loss                   | 0.735    |\n",
      "|    disc/disc_proportion_expert_pred | 0.983    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.515    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0303   |\n",
      "|    disc/disc_entropy                | 0.648    |\n",
      "|    disc/disc_loss                   | 0.731    |\n",
      "|    disc/disc_proportion_expert_pred | 0.985    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.515    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0303   |\n",
      "|    disc/disc_entropy                | 0.649    |\n",
      "|    disc/disc_loss                   | 0.729    |\n",
      "|    disc/disc_proportion_expert_pred | 0.985    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.52     |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0405   |\n",
      "|    disc/disc_entropy                | 0.65     |\n",
      "|    disc/disc_loss                   | 0.727    |\n",
      "|    disc/disc_proportion_expert_pred | 0.98     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.521    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0425   |\n",
      "|    disc/disc_entropy                | 0.652    |\n",
      "|    disc/disc_loss                   | 0.72     |\n",
      "|    disc/disc_proportion_expert_pred | 0.979    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.525    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0498   |\n",
      "|    disc/disc_entropy                | 0.654    |\n",
      "|    disc/disc_loss                   | 0.717    |\n",
      "|    disc/disc_proportion_expert_pred | 0.975    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.522    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0444   |\n",
      "|    disc/disc_entropy                | 0.655    |\n",
      "|    disc/disc_loss                   | 0.716    |\n",
      "|    disc/disc_proportion_expert_pred | 0.978    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.528    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0552   |\n",
      "|    disc/disc_entropy                | 0.656    |\n",
      "|    disc/disc_loss                   | 0.711    |\n",
      "|    disc/disc_proportion_expert_pred | 0.972    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.53     |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0605   |\n",
      "|    disc/disc_entropy                | 0.656    |\n",
      "|    disc/disc_loss                   | 0.713    |\n",
      "|    disc/disc_proportion_expert_pred | 0.97     |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "| raw/                                |          |\n",
      "|    disc/disc_acc                    | 0.533    |\n",
      "|    disc/disc_acc_expert             | 1        |\n",
      "|    disc/disc_acc_gen                | 0.0654   |\n",
      "|    disc/disc_entropy                | 0.658    |\n",
      "|    disc/disc_loss                   | 0.709    |\n",
      "|    disc/disc_proportion_expert_pred | 0.967    |\n",
      "|    disc/disc_proportion_expert_true | 0.5      |\n",
      "|    disc/global_step                 | 1        |\n",
      "|    disc/n_expert                    | 2.05e+03 |\n",
      "|    disc/n_generated                 | 2.05e+03 |\n",
      "--------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| mean/                               |           |\n",
      "|    disc/disc_acc                    | 0.518     |\n",
      "|    disc/disc_acc_expert             | 1         |\n",
      "|    disc/disc_acc_gen                | 0.0362    |\n",
      "|    disc/disc_entropy                | 0.648     |\n",
      "|    disc/disc_loss                   | 0.731     |\n",
      "|    disc/disc_proportion_expert_pred | 0.982     |\n",
      "|    disc/disc_proportion_expert_true | 0.5       |\n",
      "|    disc/global_step                 | 1         |\n",
      "|    disc/n_expert                    | 2.05e+03  |\n",
      "|    disc/n_generated                 | 2.05e+03  |\n",
      "|    gen/rollout/ep_len_mean          | 500       |\n",
      "|    gen/rollout/ep_rew_mean          | 32.6      |\n",
      "|    gen/time/fps                     | 2.65e+03  |\n",
      "|    gen/time/iterations              | 1         |\n",
      "|    gen/time/time_elapsed            | 6         |\n",
      "|    gen/time/total_timesteps         | 1.64e+04  |\n",
      "|    gen/train/approx_kl              | 0.00131   |\n",
      "|    gen/train/clip_fraction          | 0.0371    |\n",
      "|    gen/train/clip_range             | 0.1       |\n",
      "|    gen/train/entropy_loss           | -0.692    |\n",
      "|    gen/train/explained_variance     | -0.00826  |\n",
      "|    gen/train/learning_rate          | 0.0005    |\n",
      "|    gen/train/loss                   | 0.407     |\n",
      "|    gen/train/n_updates              | 5         |\n",
      "|    gen/train/policy_gradient_loss   | -0.000674 |\n",
      "|    gen/train/value_loss             | 29        |\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "round: 100%|██████████| 1/1 [00:12<00:00, 12.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards before training: 206.74 +/- 186.23751609168332\n",
      "Rewards after training: 8.31 +/- 0.7706490770772388\n",
      "Query schedule: [1, 2, 1, 1, 1, 1, 1, 1, 1]\n",
      "Collecting 2 fragments (200 transitions)\n",
      "Requested 190 transitions but only 0 in buffer. Sampling 190 additional transitions.\n",
      "Sampling 10 exploratory transitions.\n",
      "Creating fragment pairs\n",
      "Gathering preferences\n",
      "Dataset now contains 1 comparisons\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training reward model:   0%|          | 0/40 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e87efcd9acb94def88d1afda37976044"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent for 50000 timesteps\n",
      "---------------------------------------------------\n",
      "| raw/                                 |          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132     |\n",
      "|    agent/time/fps                    | 2323     |\n",
      "|    agent/time/iterations             | 1        |\n",
      "|    agent/time/time_elapsed           | 0        |\n",
      "|    agent/time/total_timesteps        | 256      |\n",
      "---------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 897         |\n",
      "|    agent/time/iterations             | 2           |\n",
      "|    agent/time/time_elapsed           | 0           |\n",
      "|    agent/time/total_timesteps        | 512         |\n",
      "|    agent/train/approx_kl             | 0.014561886 |\n",
      "|    agent/train/clip_fraction         | 0.28        |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.679      |\n",
      "|    agent/train/explained_variance    | 0.118       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0155     |\n",
      "|    agent/train/n_updates             | 20          |\n",
      "|    agent/train/policy_gradient_loss  | -0.0357     |\n",
      "|    agent/train/value_loss            | 0.274       |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132         |\n",
      "|    agent/time/fps                    | 750          |\n",
      "|    agent/time/iterations             | 3            |\n",
      "|    agent/time/time_elapsed           | 1            |\n",
      "|    agent/time/total_timesteps        | 768          |\n",
      "|    agent/train/approx_kl             | 0.0095988605 |\n",
      "|    agent/train/clip_fraction         | 0.12         |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.666       |\n",
      "|    agent/train/explained_variance    | 0.631        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0348       |\n",
      "|    agent/train/n_updates             | 40           |\n",
      "|    agent/train/policy_gradient_loss  | -0.0138      |\n",
      "|    agent/train/value_loss            | 0.499        |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 698         |\n",
      "|    agent/time/iterations             | 4           |\n",
      "|    agent/time/time_elapsed           | 1           |\n",
      "|    agent/time/total_timesteps        | 1024        |\n",
      "|    agent/train/approx_kl             | 0.013667131 |\n",
      "|    agent/train/clip_fraction         | 0.179       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.676      |\n",
      "|    agent/train/explained_variance    | 0.741       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0218      |\n",
      "|    agent/train/n_updates             | 60          |\n",
      "|    agent/train/policy_gradient_loss  | -0.0187     |\n",
      "|    agent/train/value_loss            | 0.49        |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132         |\n",
      "|    agent/time/fps                    | 659          |\n",
      "|    agent/time/iterations             | 5            |\n",
      "|    agent/time/time_elapsed           | 1            |\n",
      "|    agent/time/total_timesteps        | 1280         |\n",
      "|    agent/train/approx_kl             | 0.0156140085 |\n",
      "|    agent/train/clip_fraction         | 0.142        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.67        |\n",
      "|    agent/train/explained_variance    | 0.887        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.00558      |\n",
      "|    agent/train/n_updates             | 80           |\n",
      "|    agent/train/policy_gradient_loss  | -0.0178      |\n",
      "|    agent/train/value_loss            | 0.636        |\n",
      "-------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132       |\n",
      "|    agent/time/fps                    | 638        |\n",
      "|    agent/time/iterations             | 6          |\n",
      "|    agent/time/time_elapsed           | 2          |\n",
      "|    agent/time/total_timesteps        | 1536       |\n",
      "|    agent/train/approx_kl             | 0.00691941 |\n",
      "|    agent/train/clip_fraction         | 0.0393     |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.682     |\n",
      "|    agent/train/explained_variance    | 0.921      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | 0.0257     |\n",
      "|    agent/train/n_updates             | 100        |\n",
      "|    agent/train/policy_gradient_loss  | -0.00784   |\n",
      "|    agent/train/value_loss            | 0.974      |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 620         |\n",
      "|    agent/time/iterations             | 7           |\n",
      "|    agent/time/time_elapsed           | 2           |\n",
      "|    agent/time/total_timesteps        | 1792        |\n",
      "|    agent/train/approx_kl             | 0.016533105 |\n",
      "|    agent/train/clip_fraction         | 0.138       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.675      |\n",
      "|    agent/train/explained_variance    | 0.946       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0501      |\n",
      "|    agent/train/n_updates             | 120         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0138     |\n",
      "|    agent/train/value_loss            | 1.46        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 610         |\n",
      "|    agent/time/iterations             | 8           |\n",
      "|    agent/time/time_elapsed           | 3           |\n",
      "|    agent/time/total_timesteps        | 2048        |\n",
      "|    agent/train/approx_kl             | 0.018127631 |\n",
      "|    agent/train/clip_fraction         | 0.26        |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.655      |\n",
      "|    agent/train/explained_variance    | 0.955       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0153      |\n",
      "|    agent/train/n_updates             | 140         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0255     |\n",
      "|    agent/train/value_loss            | 1.22        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 604         |\n",
      "|    agent/time/iterations             | 9           |\n",
      "|    agent/time/time_elapsed           | 3           |\n",
      "|    agent/time/total_timesteps        | 2304        |\n",
      "|    agent/train/approx_kl             | 0.016708305 |\n",
      "|    agent/train/clip_fraction         | 0.13        |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.606      |\n",
      "|    agent/train/explained_variance    | 0.974       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.01       |\n",
      "|    agent/train/n_updates             | 160         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0185     |\n",
      "|    agent/train/value_loss            | 0.767       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 602         |\n",
      "|    agent/time/iterations             | 10          |\n",
      "|    agent/time/time_elapsed           | 4           |\n",
      "|    agent/time/total_timesteps        | 2560        |\n",
      "|    agent/train/approx_kl             | 0.009051822 |\n",
      "|    agent/train/clip_fraction         | 0.156       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.576      |\n",
      "|    agent/train/explained_variance    | 0.979       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0343      |\n",
      "|    agent/train/n_updates             | 180         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0125     |\n",
      "|    agent/train/value_loss            | 1.1         |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 597         |\n",
      "|    agent/time/iterations             | 11          |\n",
      "|    agent/time/time_elapsed           | 4           |\n",
      "|    agent/time/total_timesteps        | 2816        |\n",
      "|    agent/train/approx_kl             | 0.024958365 |\n",
      "|    agent/train/clip_fraction         | 0.218       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.554      |\n",
      "|    agent/train/explained_variance    | 0.979       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0162     |\n",
      "|    agent/train/n_updates             | 200         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0159     |\n",
      "|    agent/train/value_loss            | 0.978       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 591         |\n",
      "|    agent/time/iterations             | 12          |\n",
      "|    agent/time/time_elapsed           | 5           |\n",
      "|    agent/time/total_timesteps        | 3072        |\n",
      "|    agent/train/approx_kl             | 0.008603798 |\n",
      "|    agent/train/clip_fraction         | 0.0904      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.536      |\n",
      "|    agent/train/explained_variance    | 0.978       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.027       |\n",
      "|    agent/train/n_updates             | 220         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00739    |\n",
      "|    agent/train/value_loss            | 1.45        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 588         |\n",
      "|    agent/time/iterations             | 13          |\n",
      "|    agent/time/time_elapsed           | 5           |\n",
      "|    agent/time/total_timesteps        | 3328        |\n",
      "|    agent/train/approx_kl             | 0.015982304 |\n",
      "|    agent/train/clip_fraction         | 0.246       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.562      |\n",
      "|    agent/train/explained_variance    | 0.973       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.128       |\n",
      "|    agent/train/n_updates             | 240         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0216     |\n",
      "|    agent/train/value_loss            | 1.88        |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132       |\n",
      "|    agent/time/fps                    | 587        |\n",
      "|    agent/time/iterations             | 14         |\n",
      "|    agent/time/time_elapsed           | 6          |\n",
      "|    agent/time/total_timesteps        | 3584       |\n",
      "|    agent/train/approx_kl             | 0.02174624 |\n",
      "|    agent/train/clip_fraction         | 0.184      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.557     |\n",
      "|    agent/train/explained_variance    | 0.967      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | 0.115      |\n",
      "|    agent/train/n_updates             | 260        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0188    |\n",
      "|    agent/train/value_loss            | 2.26       |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 585         |\n",
      "|    agent/time/iterations             | 15          |\n",
      "|    agent/time/time_elapsed           | 6           |\n",
      "|    agent/time/total_timesteps        | 3840        |\n",
      "|    agent/train/approx_kl             | 0.018407391 |\n",
      "|    agent/train/clip_fraction         | 0.196       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.613      |\n",
      "|    agent/train/explained_variance    | 0.965       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0218      |\n",
      "|    agent/train/n_updates             | 280         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0112     |\n",
      "|    agent/train/value_loss            | 1.23        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -132        |\n",
      "|    agent/time/fps                    | 582         |\n",
      "|    agent/time/iterations             | 16          |\n",
      "|    agent/time/time_elapsed           | 7           |\n",
      "|    agent/time/total_timesteps        | 4096        |\n",
      "|    agent/train/approx_kl             | 0.011909256 |\n",
      "|    agent/train/clip_fraction         | 0.211       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.596      |\n",
      "|    agent/train/explained_variance    | 0.916       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0444      |\n",
      "|    agent/train/n_updates             | 300         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0171     |\n",
      "|    agent/train/value_loss            | 1.98        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 577         |\n",
      "|    agent/time/iterations             | 17          |\n",
      "|    agent/time/time_elapsed           | 7           |\n",
      "|    agent/time/total_timesteps        | 4352        |\n",
      "|    agent/train/approx_kl             | 0.015841894 |\n",
      "|    agent/train/clip_fraction         | 0.193       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.602      |\n",
      "|    agent/train/explained_variance    | 0.908       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0714      |\n",
      "|    agent/train/n_updates             | 320         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0207     |\n",
      "|    agent/train/value_loss            | 2.34        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 576         |\n",
      "|    agent/time/iterations             | 18          |\n",
      "|    agent/time/time_elapsed           | 7           |\n",
      "|    agent/time/total_timesteps        | 4608        |\n",
      "|    agent/train/approx_kl             | 0.019959278 |\n",
      "|    agent/train/clip_fraction         | 0.309       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.556      |\n",
      "|    agent/train/explained_variance    | 0.965       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0163     |\n",
      "|    agent/train/n_updates             | 340         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0332     |\n",
      "|    agent/train/value_loss            | 0.711       |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 26           |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135         |\n",
      "|    agent/time/fps                    | 573          |\n",
      "|    agent/time/iterations             | 19           |\n",
      "|    agent/time/time_elapsed           | 8            |\n",
      "|    agent/time/total_timesteps        | 4864         |\n",
      "|    agent/train/approx_kl             | 0.0123888925 |\n",
      "|    agent/train/clip_fraction         | 0.211        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.482       |\n",
      "|    agent/train/explained_variance    | 0.86         |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0346       |\n",
      "|    agent/train/n_updates             | 360          |\n",
      "|    agent/train/policy_gradient_loss  | -0.0192      |\n",
      "|    agent/train/value_loss            | 0.902        |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 572         |\n",
      "|    agent/time/iterations             | 20          |\n",
      "|    agent/time/time_elapsed           | 8           |\n",
      "|    agent/time/total_timesteps        | 5120        |\n",
      "|    agent/train/approx_kl             | 0.023867685 |\n",
      "|    agent/train/clip_fraction         | 0.227       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.528      |\n",
      "|    agent/train/explained_variance    | 0.935       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0211     |\n",
      "|    agent/train/n_updates             | 380         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0347     |\n",
      "|    agent/train/value_loss            | 0.509       |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 26         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135       |\n",
      "|    agent/time/fps                    | 570        |\n",
      "|    agent/time/iterations             | 21         |\n",
      "|    agent/time/time_elapsed           | 9          |\n",
      "|    agent/time/total_timesteps        | 5376       |\n",
      "|    agent/train/approx_kl             | 0.02620761 |\n",
      "|    agent/train/clip_fraction         | 0.202      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.49      |\n",
      "|    agent/train/explained_variance    | 0.886      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | 0.0477     |\n",
      "|    agent/train/n_updates             | 400        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0207    |\n",
      "|    agent/train/value_loss            | 0.537      |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 567         |\n",
      "|    agent/time/iterations             | 22          |\n",
      "|    agent/time/time_elapsed           | 9           |\n",
      "|    agent/time/total_timesteps        | 5632        |\n",
      "|    agent/train/approx_kl             | 0.021604843 |\n",
      "|    agent/train/clip_fraction         | 0.212       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.455      |\n",
      "|    agent/train/explained_variance    | 0.834       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0167      |\n",
      "|    agent/train/n_updates             | 420         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0172     |\n",
      "|    agent/train/value_loss            | 0.445       |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 26         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135       |\n",
      "|    agent/time/fps                    | 565        |\n",
      "|    agent/time/iterations             | 23         |\n",
      "|    agent/time/time_elapsed           | 10         |\n",
      "|    agent/time/total_timesteps        | 5888       |\n",
      "|    agent/train/approx_kl             | 0.01065169 |\n",
      "|    agent/train/clip_fraction         | 0.158      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.447     |\n",
      "|    agent/train/explained_variance    | 0.887      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | -0.0365    |\n",
      "|    agent/train/n_updates             | 440        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0159    |\n",
      "|    agent/train/value_loss            | 0.191      |\n",
      "-----------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 26           |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135         |\n",
      "|    agent/time/fps                    | 563          |\n",
      "|    agent/time/iterations             | 24           |\n",
      "|    agent/time/time_elapsed           | 10           |\n",
      "|    agent/time/total_timesteps        | 6144         |\n",
      "|    agent/train/approx_kl             | 0.0076224655 |\n",
      "|    agent/train/clip_fraction         | 0.153        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.459       |\n",
      "|    agent/train/explained_variance    | 0.797        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.00295      |\n",
      "|    agent/train/n_updates             | 460          |\n",
      "|    agent/train/policy_gradient_loss  | -0.0146      |\n",
      "|    agent/train/value_loss            | 0.191        |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 560         |\n",
      "|    agent/time/iterations             | 25          |\n",
      "|    agent/time/time_elapsed           | 11          |\n",
      "|    agent/time/total_timesteps        | 6400        |\n",
      "|    agent/train/approx_kl             | 0.011324159 |\n",
      "|    agent/train/clip_fraction         | 0.134       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.446      |\n",
      "|    agent/train/explained_variance    | 0.907       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.00123    |\n",
      "|    agent/train/n_updates             | 480         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0136     |\n",
      "|    agent/train/value_loss            | 0.138       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 557         |\n",
      "|    agent/time/iterations             | 26          |\n",
      "|    agent/time/time_elapsed           | 11          |\n",
      "|    agent/time/total_timesteps        | 6656        |\n",
      "|    agent/train/approx_kl             | 0.021766573 |\n",
      "|    agent/train/clip_fraction         | 0.198       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.416      |\n",
      "|    agent/train/explained_variance    | 0.931       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0155     |\n",
      "|    agent/train/n_updates             | 500         |\n",
      "|    agent/train/policy_gradient_loss  | -0.024      |\n",
      "|    agent/train/value_loss            | 0.144       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 557         |\n",
      "|    agent/time/iterations             | 27          |\n",
      "|    agent/time/time_elapsed           | 12          |\n",
      "|    agent/time/total_timesteps        | 6912        |\n",
      "|    agent/train/approx_kl             | 0.049199674 |\n",
      "|    agent/train/clip_fraction         | 0.131       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.343      |\n",
      "|    agent/train/explained_variance    | 0.956       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.00886    |\n",
      "|    agent/train/n_updates             | 520         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0173     |\n",
      "|    agent/train/value_loss            | 0.13        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 556         |\n",
      "|    agent/time/iterations             | 28          |\n",
      "|    agent/time/time_elapsed           | 12          |\n",
      "|    agent/time/total_timesteps        | 7168        |\n",
      "|    agent/train/approx_kl             | 0.008877063 |\n",
      "|    agent/train/clip_fraction         | 0.0711      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.258      |\n",
      "|    agent/train/explained_variance    | 0.961       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0074     |\n",
      "|    agent/train/n_updates             | 540         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00798    |\n",
      "|    agent/train/value_loss            | 0.175       |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 26           |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135         |\n",
      "|    agent/time/fps                    | 555          |\n",
      "|    agent/time/iterations             | 29           |\n",
      "|    agent/time/time_elapsed           | 13           |\n",
      "|    agent/time/total_timesteps        | 7424         |\n",
      "|    agent/train/approx_kl             | 0.0038015302 |\n",
      "|    agent/train/clip_fraction         | 0.0688       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.253       |\n",
      "|    agent/train/explained_variance    | 0.94         |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | -0.0016      |\n",
      "|    agent/train/n_updates             | 560          |\n",
      "|    agent/train/policy_gradient_loss  | -0.00586     |\n",
      "|    agent/train/value_loss            | 0.327        |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 26          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135        |\n",
      "|    agent/time/fps                    | 554         |\n",
      "|    agent/time/iterations             | 30          |\n",
      "|    agent/time/time_elapsed           | 13          |\n",
      "|    agent/time/total_timesteps        | 7680        |\n",
      "|    agent/train/approx_kl             | 0.010277461 |\n",
      "|    agent/train/clip_fraction         | 0.0422      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.244      |\n",
      "|    agent/train/explained_variance    | 0.929       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0707      |\n",
      "|    agent/train/n_updates             | 580         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00131    |\n",
      "|    agent/train/value_loss            | 0.679       |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 26           |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135         |\n",
      "|    agent/time/fps                    | 554          |\n",
      "|    agent/time/iterations             | 31           |\n",
      "|    agent/time/time_elapsed           | 14           |\n",
      "|    agent/time/total_timesteps        | 7936         |\n",
      "|    agent/train/approx_kl             | 0.0055421647 |\n",
      "|    agent/train/clip_fraction         | 0.0725       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.23        |\n",
      "|    agent/train/explained_variance    | 0.936        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0234       |\n",
      "|    agent/train/n_updates             | 600          |\n",
      "|    agent/train/policy_gradient_loss  | -0.00923     |\n",
      "|    agent/train/value_loss            | 1.15         |\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -135         |\n",
      "|    agent/time/fps                    | 553          |\n",
      "|    agent/time/iterations             | 32           |\n",
      "|    agent/time/time_elapsed           | 14           |\n",
      "|    agent/time/total_timesteps        | 8192         |\n",
      "|    agent/train/approx_kl             | 0.0038635768 |\n",
      "|    agent/train/clip_fraction         | 0.0371       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.225       |\n",
      "|    agent/train/explained_variance    | 0.95         |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0354       |\n",
      "|    agent/train/n_updates             | 620          |\n",
      "|    agent/train/policy_gradient_loss  | -0.000331    |\n",
      "|    agent/train/value_loss            | 1.33         |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 554         |\n",
      "|    agent/time/iterations             | 33          |\n",
      "|    agent/time/time_elapsed           | 15          |\n",
      "|    agent/time/total_timesteps        | 8448        |\n",
      "|    agent/train/approx_kl             | 0.008352287 |\n",
      "|    agent/train/clip_fraction         | 0.0902      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.491      |\n",
      "|    agent/train/explained_variance    | 0.978       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0417      |\n",
      "|    agent/train/n_updates             | 640         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0114     |\n",
      "|    agent/train/value_loss            | 0.597       |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3        |\n",
      "|    agent/time/fps                    | 553          |\n",
      "|    agent/time/iterations             | 34           |\n",
      "|    agent/time/time_elapsed           | 15           |\n",
      "|    agent/time/total_timesteps        | 8704         |\n",
      "|    agent/train/approx_kl             | 0.0077915383 |\n",
      "|    agent/train/clip_fraction         | 0.0639       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.3         |\n",
      "|    agent/train/explained_variance    | 0.986        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.00337      |\n",
      "|    agent/train/n_updates             | 660          |\n",
      "|    agent/train/policy_gradient_loss  | -0.00581     |\n",
      "|    agent/train/value_loss            | 0.0198       |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 553         |\n",
      "|    agent/time/iterations             | 35          |\n",
      "|    agent/time/time_elapsed           | 16          |\n",
      "|    agent/time/total_timesteps        | 8960        |\n",
      "|    agent/train/approx_kl             | 0.003884025 |\n",
      "|    agent/train/clip_fraction         | 0.0809      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.272      |\n",
      "|    agent/train/explained_variance    | 0.424       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0448      |\n",
      "|    agent/train/n_updates             | 680         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00587    |\n",
      "|    agent/train/value_loss            | 1.37        |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3        |\n",
      "|    agent/time/fps                    | 554          |\n",
      "|    agent/time/iterations             | 36           |\n",
      "|    agent/time/time_elapsed           | 16           |\n",
      "|    agent/time/total_timesteps        | 9216         |\n",
      "|    agent/train/approx_kl             | 0.0058897333 |\n",
      "|    agent/train/clip_fraction         | 0.074        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.285       |\n",
      "|    agent/train/explained_variance    | 0.762        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | -0.00522     |\n",
      "|    agent/train/n_updates             | 700          |\n",
      "|    agent/train/policy_gradient_loss  | -0.0129      |\n",
      "|    agent/train/value_loss            | 1.11         |\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3        |\n",
      "|    agent/time/fps                    | 553          |\n",
      "|    agent/time/iterations             | 37           |\n",
      "|    agent/time/time_elapsed           | 17           |\n",
      "|    agent/time/total_timesteps        | 9472         |\n",
      "|    agent/train/approx_kl             | 0.0065176096 |\n",
      "|    agent/train/clip_fraction         | 0.128        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.231       |\n",
      "|    agent/train/explained_variance    | 0.586        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | -0.014       |\n",
      "|    agent/train/n_updates             | 720          |\n",
      "|    agent/train/policy_gradient_loss  | -0.0232      |\n",
      "|    agent/train/value_loss            | 0.553        |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 553         |\n",
      "|    agent/time/iterations             | 38          |\n",
      "|    agent/time/time_elapsed           | 17          |\n",
      "|    agent/time/total_timesteps        | 9728        |\n",
      "|    agent/train/approx_kl             | 0.013271181 |\n",
      "|    agent/train/clip_fraction         | 0.134       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.237      |\n",
      "|    agent/train/explained_variance    | 0.485       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0337      |\n",
      "|    agent/train/n_updates             | 740         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0201     |\n",
      "|    agent/train/value_loss            | 0.968       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 553         |\n",
      "|    agent/time/iterations             | 39          |\n",
      "|    agent/time/time_elapsed           | 18          |\n",
      "|    agent/time/total_timesteps        | 9984        |\n",
      "|    agent/train/approx_kl             | 0.043200165 |\n",
      "|    agent/train/clip_fraction         | 0.166       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.171      |\n",
      "|    agent/train/explained_variance    | -0.16       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.00961     |\n",
      "|    agent/train/n_updates             | 760         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0179     |\n",
      "|    agent/train/value_loss            | 0.9         |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 552         |\n",
      "|    agent/time/iterations             | 40          |\n",
      "|    agent/time/time_elapsed           | 18          |\n",
      "|    agent/time/total_timesteps        | 10240       |\n",
      "|    agent/train/approx_kl             | 0.004030381 |\n",
      "|    agent/train/clip_fraction         | 0.0355      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.118      |\n",
      "|    agent/train/explained_variance    | 0.125       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0184      |\n",
      "|    agent/train/n_updates             | 780         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00547    |\n",
      "|    agent/train/value_loss            | 0.518       |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3      |\n",
      "|    agent/time/fps                    | 553        |\n",
      "|    agent/time/iterations             | 41         |\n",
      "|    agent/time/time_elapsed           | 18         |\n",
      "|    agent/time/total_timesteps        | 10496      |\n",
      "|    agent/train/approx_kl             | 0.22172558 |\n",
      "|    agent/train/clip_fraction         | 0.186      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.218     |\n",
      "|    agent/train/explained_variance    | 0.476      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | -0.0337    |\n",
      "|    agent/train/n_updates             | 800        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0434    |\n",
      "|    agent/train/value_loss            | 0.512      |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 553         |\n",
      "|    agent/time/iterations             | 42          |\n",
      "|    agent/time/time_elapsed           | 19          |\n",
      "|    agent/time/total_timesteps        | 10752       |\n",
      "|    agent/train/approx_kl             | 0.022193603 |\n",
      "|    agent/train/clip_fraction         | 0.2         |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.301      |\n",
      "|    agent/train/explained_variance    | 0.719       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0175      |\n",
      "|    agent/train/n_updates             | 820         |\n",
      "|    agent/train/policy_gradient_loss  | -0.018      |\n",
      "|    agent/train/value_loss            | 0.201       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 553         |\n",
      "|    agent/time/iterations             | 43          |\n",
      "|    agent/time/time_elapsed           | 19          |\n",
      "|    agent/time/total_timesteps        | 11008       |\n",
      "|    agent/train/approx_kl             | 0.012412885 |\n",
      "|    agent/train/clip_fraction         | 0.148       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.266      |\n",
      "|    agent/train/explained_variance    | 0.757       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0111     |\n",
      "|    agent/train/n_updates             | 840         |\n",
      "|    agent/train/policy_gradient_loss  | -0.022      |\n",
      "|    agent/train/value_loss            | 0.122       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 553         |\n",
      "|    agent/time/iterations             | 44          |\n",
      "|    agent/time/time_elapsed           | 20          |\n",
      "|    agent/time/total_timesteps        | 11264       |\n",
      "|    agent/train/approx_kl             | 0.008367339 |\n",
      "|    agent/train/clip_fraction         | 0.117       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.262      |\n",
      "|    agent/train/explained_variance    | 0.898       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0109     |\n",
      "|    agent/train/n_updates             | 860         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0159     |\n",
      "|    agent/train/value_loss            | 0.199       |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3        |\n",
      "|    agent/time/fps                    | 553          |\n",
      "|    agent/time/iterations             | 45           |\n",
      "|    agent/time/time_elapsed           | 20           |\n",
      "|    agent/time/total_timesteps        | 11520        |\n",
      "|    agent/train/approx_kl             | 0.0125284875 |\n",
      "|    agent/train/clip_fraction         | 0.189        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.251       |\n",
      "|    agent/train/explained_variance    | 0.919        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | -0.0159      |\n",
      "|    agent/train/n_updates             | 880          |\n",
      "|    agent/train/policy_gradient_loss  | -0.0203      |\n",
      "|    agent/train/value_loss            | 0.323        |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 24.8        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3       |\n",
      "|    agent/time/fps                    | 552         |\n",
      "|    agent/time/iterations             | 46          |\n",
      "|    agent/time/time_elapsed           | 21          |\n",
      "|    agent/time/total_timesteps        | 11776       |\n",
      "|    agent/train/approx_kl             | 0.007153832 |\n",
      "|    agent/train/clip_fraction         | 0.125       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.227      |\n",
      "|    agent/train/explained_variance    | 0.939       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0258      |\n",
      "|    agent/train/n_updates             | 900         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0112     |\n",
      "|    agent/train/value_loss            | 0.397       |\n",
      "------------------------------------------------------\n",
      "---------------------------------------------------\n",
      "| raw/                                 |          |\n",
      "|    agent/rollout/ep_len_mean         | 500      |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9     |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -94.3    |\n",
      "|    agent/time/fps                    | 552      |\n",
      "|    agent/time/iterations             | 47       |\n",
      "|    agent/time/time_elapsed           | 21       |\n",
      "|    agent/time/total_timesteps        | 12032    |\n",
      "|    agent/train/approx_kl             | 0.057432 |\n",
      "|    agent/train/clip_fraction         | 0.146    |\n",
      "|    agent/train/clip_range            | 0.2      |\n",
      "|    agent/train/entropy_loss          | -0.209   |\n",
      "|    agent/train/explained_variance    | 0.947    |\n",
      "|    agent/train/learning_rate         | 0.001    |\n",
      "|    agent/train/loss                  | 0.000365 |\n",
      "|    agent/train/n_updates             | 920      |\n",
      "|    agent/train/policy_gradient_loss  | -0.0136  |\n",
      "|    agent/train/value_loss            | 0.432    |\n",
      "---------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 552         |\n",
      "|    agent/time/iterations             | 48          |\n",
      "|    agent/time/time_elapsed           | 22          |\n",
      "|    agent/time/total_timesteps        | 12288       |\n",
      "|    agent/train/approx_kl             | 0.005192682 |\n",
      "|    agent/train/clip_fraction         | 0.0824      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.21       |\n",
      "|    agent/train/explained_variance    | 0.979       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.00945     |\n",
      "|    agent/train/n_updates             | 940         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00939    |\n",
      "|    agent/train/value_loss            | 0.451       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 552         |\n",
      "|    agent/time/iterations             | 49          |\n",
      "|    agent/time/time_elapsed           | 22          |\n",
      "|    agent/time/total_timesteps        | 12544       |\n",
      "|    agent/train/approx_kl             | 0.018071111 |\n",
      "|    agent/train/clip_fraction         | 0.138       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.501      |\n",
      "|    agent/train/explained_variance    | 0.972       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0109     |\n",
      "|    agent/train/n_updates             | 960         |\n",
      "|    agent/train/policy_gradient_loss  | -0.013      |\n",
      "|    agent/train/value_loss            | 0.83        |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 552          |\n",
      "|    agent/time/iterations             | 50           |\n",
      "|    agent/time/time_elapsed           | 23           |\n",
      "|    agent/time/total_timesteps        | 12800        |\n",
      "|    agent/train/approx_kl             | 0.0014290789 |\n",
      "|    agent/train/clip_fraction         | 0.0135       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.249       |\n",
      "|    agent/train/explained_variance    | 0.545        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.116        |\n",
      "|    agent/train/n_updates             | 980          |\n",
      "|    agent/train/policy_gradient_loss  | -0.000591    |\n",
      "|    agent/train/value_loss            | 2.85         |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 51          |\n",
      "|    agent/time/time_elapsed           | 23          |\n",
      "|    agent/time/total_timesteps        | 13056       |\n",
      "|    agent/train/approx_kl             | 0.006351041 |\n",
      "|    agent/train/clip_fraction         | 0.023       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.163      |\n",
      "|    agent/train/explained_variance    | 0.868       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0272      |\n",
      "|    agent/train/n_updates             | 1000        |\n",
      "|    agent/train/policy_gradient_loss  | -0.00674    |\n",
      "|    agent/train/value_loss            | 0.969       |\n",
      "------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "| raw/                                 |               |\n",
      "|    agent/rollout/ep_len_mean         | 500           |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9          |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123          |\n",
      "|    agent/time/fps                    | 549           |\n",
      "|    agent/time/iterations             | 52            |\n",
      "|    agent/time/time_elapsed           | 24            |\n",
      "|    agent/time/total_timesteps        | 13312         |\n",
      "|    agent/train/approx_kl             | 0.00075821544 |\n",
      "|    agent/train/clip_fraction         | 0.0115        |\n",
      "|    agent/train/clip_range            | 0.2           |\n",
      "|    agent/train/entropy_loss          | -0.155        |\n",
      "|    agent/train/explained_variance    | 0.498         |\n",
      "|    agent/train/learning_rate         | 0.001         |\n",
      "|    agent/train/loss                  | 0.0759        |\n",
      "|    agent/train/n_updates             | 1020          |\n",
      "|    agent/train/policy_gradient_loss  | -0.00214      |\n",
      "|    agent/train/value_loss            | 1.4           |\n",
      "--------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 549          |\n",
      "|    agent/time/iterations             | 53           |\n",
      "|    agent/time/time_elapsed           | 24           |\n",
      "|    agent/time/total_timesteps        | 13568        |\n",
      "|    agent/train/approx_kl             | 0.0036619822 |\n",
      "|    agent/train/clip_fraction         | 0.0287       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.162       |\n",
      "|    agent/train/explained_variance    | 0.224        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0546       |\n",
      "|    agent/train/n_updates             | 1040         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00567     |\n",
      "|    agent/train/value_loss            | 1.25         |\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 550          |\n",
      "|    agent/time/iterations             | 54           |\n",
      "|    agent/time/time_elapsed           | 25           |\n",
      "|    agent/time/total_timesteps        | 13824        |\n",
      "|    agent/train/approx_kl             | 0.0019334763 |\n",
      "|    agent/train/clip_fraction         | 0.0229       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.138       |\n",
      "|    agent/train/explained_variance    | 0.502        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0825       |\n",
      "|    agent/train/n_updates             | 1060         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00549     |\n",
      "|    agent/train/value_loss            | 1.44         |\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 550          |\n",
      "|    agent/time/iterations             | 55           |\n",
      "|    agent/time/time_elapsed           | 25           |\n",
      "|    agent/time/total_timesteps        | 14080        |\n",
      "|    agent/train/approx_kl             | 0.0032567787 |\n",
      "|    agent/train/clip_fraction         | 0.018        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.113       |\n",
      "|    agent/train/explained_variance    | 0.155        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0689       |\n",
      "|    agent/train/n_updates             | 1080         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00383     |\n",
      "|    agent/train/value_loss            | 1.77         |\n",
      "-------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 550          |\n",
      "|    agent/time/iterations             | 56           |\n",
      "|    agent/time/time_elapsed           | 26           |\n",
      "|    agent/time/total_timesteps        | 14336        |\n",
      "|    agent/train/approx_kl             | 0.0035249575 |\n",
      "|    agent/train/clip_fraction         | 0.0318       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.109       |\n",
      "|    agent/train/explained_variance    | 0.0505       |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0683       |\n",
      "|    agent/train/n_updates             | 1100         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00355     |\n",
      "|    agent/train/value_loss            | 1.31         |\n",
      "-------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123       |\n",
      "|    agent/time/fps                    | 550        |\n",
      "|    agent/time/iterations             | 57         |\n",
      "|    agent/time/time_elapsed           | 26         |\n",
      "|    agent/time/total_timesteps        | 14592      |\n",
      "|    agent/train/approx_kl             | 0.05318826 |\n",
      "|    agent/train/clip_fraction         | 0.117      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.185     |\n",
      "|    agent/train/explained_variance    | 0.199      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | -0.01      |\n",
      "|    agent/train/n_updates             | 1120       |\n",
      "|    agent/train/policy_gradient_loss  | -0.0118    |\n",
      "|    agent/train/value_loss            | 0.799      |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 550         |\n",
      "|    agent/time/iterations             | 58          |\n",
      "|    agent/time/time_elapsed           | 26          |\n",
      "|    agent/time/total_timesteps        | 14848       |\n",
      "|    agent/train/approx_kl             | 0.011097022 |\n",
      "|    agent/train/clip_fraction         | 0.122       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.342      |\n",
      "|    agent/train/explained_variance    | 0.677       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0203      |\n",
      "|    agent/train/n_updates             | 1140        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0109     |\n",
      "|    agent/train/value_loss            | 0.586       |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123       |\n",
      "|    agent/time/fps                    | 550        |\n",
      "|    agent/time/iterations             | 59         |\n",
      "|    agent/time/time_elapsed           | 27         |\n",
      "|    agent/time/total_timesteps        | 15104      |\n",
      "|    agent/train/approx_kl             | 0.01489621 |\n",
      "|    agent/train/clip_fraction         | 0.155      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.422     |\n",
      "|    agent/train/explained_variance    | 0.878      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | 0.0191     |\n",
      "|    agent/train/n_updates             | 1160       |\n",
      "|    agent/train/policy_gradient_loss  | -0.0109    |\n",
      "|    agent/train/value_loss            | 0.412      |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 550         |\n",
      "|    agent/time/iterations             | 60          |\n",
      "|    agent/time/time_elapsed           | 27          |\n",
      "|    agent/time/total_timesteps        | 15360       |\n",
      "|    agent/train/approx_kl             | 0.014247764 |\n",
      "|    agent/train/clip_fraction         | 0.188       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.406      |\n",
      "|    agent/train/explained_variance    | 0.83        |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.00134     |\n",
      "|    agent/train/n_updates             | 1180        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0188     |\n",
      "|    agent/train/value_loss            | 0.8         |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123       |\n",
      "|    agent/time/fps                    | 550        |\n",
      "|    agent/time/iterations             | 61         |\n",
      "|    agent/time/time_elapsed           | 28         |\n",
      "|    agent/time/total_timesteps        | 15616      |\n",
      "|    agent/train/approx_kl             | 0.22507504 |\n",
      "|    agent/train/clip_fraction         | 0.242      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.342     |\n",
      "|    agent/train/explained_variance    | 0.877      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | -0.0331    |\n",
      "|    agent/train/n_updates             | 1200       |\n",
      "|    agent/train/policy_gradient_loss  | -0.0285    |\n",
      "|    agent/train/value_loss            | 0.495      |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 21.9        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 550         |\n",
      "|    agent/time/iterations             | 62          |\n",
      "|    agent/time/time_elapsed           | 28          |\n",
      "|    agent/time/total_timesteps        | 15872       |\n",
      "|    agent/train/approx_kl             | 0.009375071 |\n",
      "|    agent/train/clip_fraction         | 0.0729      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.274      |\n",
      "|    agent/train/explained_variance    | 0.889       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.018       |\n",
      "|    agent/train/n_updates             | 1220        |\n",
      "|    agent/train/policy_gradient_loss  | -0.00799    |\n",
      "|    agent/train/value_loss            | 0.486       |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123       |\n",
      "|    agent/time/fps                    | 549        |\n",
      "|    agent/time/iterations             | 63         |\n",
      "|    agent/time/time_elapsed           | 29         |\n",
      "|    agent/time/total_timesteps        | 16128      |\n",
      "|    agent/train/approx_kl             | 0.00791908 |\n",
      "|    agent/train/clip_fraction         | 0.0871     |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.34      |\n",
      "|    agent/train/explained_variance    | 0.923      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | 0.0254     |\n",
      "|    agent/train/n_updates             | 1240       |\n",
      "|    agent/train/policy_gradient_loss  | -0.0196    |\n",
      "|    agent/train/value_loss            | 1.77       |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 64          |\n",
      "|    agent/time/time_elapsed           | 29          |\n",
      "|    agent/time/total_timesteps        | 16384       |\n",
      "|    agent/train/approx_kl             | 0.018563673 |\n",
      "|    agent/train/clip_fraction         | 0.387       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.432      |\n",
      "|    agent/train/explained_variance    | 0.97        |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.00873    |\n",
      "|    agent/train/n_updates             | 1260        |\n",
      "|    agent/train/policy_gradient_loss  | -0.04       |\n",
      "|    agent/train/value_loss            | 0.789       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 65          |\n",
      "|    agent/time/time_elapsed           | 30          |\n",
      "|    agent/time/total_timesteps        | 16640       |\n",
      "|    agent/train/approx_kl             | 0.014381272 |\n",
      "|    agent/train/clip_fraction         | 0.243       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.543      |\n",
      "|    agent/train/explained_variance    | 0.66        |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0518      |\n",
      "|    agent/train/n_updates             | 1280        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0333     |\n",
      "|    agent/train/value_loss            | 0.784       |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145       |\n",
      "|    agent/time/fps                    | 549        |\n",
      "|    agent/time/iterations             | 66         |\n",
      "|    agent/time/time_elapsed           | 30         |\n",
      "|    agent/time/total_timesteps        | 16896      |\n",
      "|    agent/train/approx_kl             | 0.05623117 |\n",
      "|    agent/train/clip_fraction         | 0.198      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.521     |\n",
      "|    agent/train/explained_variance    | 0.962      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | -0.0254    |\n",
      "|    agent/train/n_updates             | 1300       |\n",
      "|    agent/train/policy_gradient_loss  | -0.0304    |\n",
      "|    agent/train/value_loss            | 1.06       |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145       |\n",
      "|    agent/time/fps                    | 549        |\n",
      "|    agent/time/iterations             | 67         |\n",
      "|    agent/time/time_elapsed           | 31         |\n",
      "|    agent/time/total_timesteps        | 17152      |\n",
      "|    agent/train/approx_kl             | 0.02015559 |\n",
      "|    agent/train/clip_fraction         | 0.128      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.433     |\n",
      "|    agent/train/explained_variance    | 0.858      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | 0.00617    |\n",
      "|    agent/train/n_updates             | 1320       |\n",
      "|    agent/train/policy_gradient_loss  | -0.00989   |\n",
      "|    agent/train/value_loss            | 0.439      |\n",
      "-----------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145         |\n",
      "|    agent/time/fps                    | 549          |\n",
      "|    agent/time/iterations             | 68           |\n",
      "|    agent/time/time_elapsed           | 31           |\n",
      "|    agent/time/total_timesteps        | 17408        |\n",
      "|    agent/train/approx_kl             | 0.0153178815 |\n",
      "|    agent/train/clip_fraction         | 0.109        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.256       |\n",
      "|    agent/train/explained_variance    | 0.724        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0162       |\n",
      "|    agent/train/n_updates             | 1340         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00985     |\n",
      "|    agent/train/value_loss            | 1.16         |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 69          |\n",
      "|    agent/time/time_elapsed           | 32          |\n",
      "|    agent/time/total_timesteps        | 17664       |\n",
      "|    agent/train/approx_kl             | 0.013162332 |\n",
      "|    agent/train/clip_fraction         | 0.133       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.316      |\n",
      "|    agent/train/explained_variance    | 0.221       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0578      |\n",
      "|    agent/train/n_updates             | 1360        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0157     |\n",
      "|    agent/train/value_loss            | 1.93        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 548         |\n",
      "|    agent/time/iterations             | 70          |\n",
      "|    agent/time/time_elapsed           | 32          |\n",
      "|    agent/time/total_timesteps        | 17920       |\n",
      "|    agent/train/approx_kl             | 0.042344473 |\n",
      "|    agent/train/clip_fraction         | 0.107       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.275      |\n",
      "|    agent/train/explained_variance    | 0.805       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0141      |\n",
      "|    agent/train/n_updates             | 1380        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0125     |\n",
      "|    agent/train/value_loss            | 0.457       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 71          |\n",
      "|    agent/time/time_elapsed           | 33          |\n",
      "|    agent/time/total_timesteps        | 18176       |\n",
      "|    agent/train/approx_kl             | 0.010459014 |\n",
      "|    agent/train/clip_fraction         | 0.122       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.342      |\n",
      "|    agent/train/explained_variance    | 0.885       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0162     |\n",
      "|    agent/train/n_updates             | 1400        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0138     |\n",
      "|    agent/train/value_loss            | 0.255       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 72          |\n",
      "|    agent/time/time_elapsed           | 33          |\n",
      "|    agent/time/total_timesteps        | 18432       |\n",
      "|    agent/train/approx_kl             | 0.009693189 |\n",
      "|    agent/train/clip_fraction         | 0.127       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.4        |\n",
      "|    agent/train/explained_variance    | 0.935       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.0127     |\n",
      "|    agent/train/n_updates             | 1420        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0154     |\n",
      "|    agent/train/value_loss            | 0.455       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 73          |\n",
      "|    agent/time/time_elapsed           | 34          |\n",
      "|    agent/time/total_timesteps        | 18688       |\n",
      "|    agent/train/approx_kl             | 0.013263455 |\n",
      "|    agent/train/clip_fraction         | 0.189       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.406      |\n",
      "|    agent/train/explained_variance    | 0.91        |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0238      |\n",
      "|    agent/train/n_updates             | 1440        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0271     |\n",
      "|    agent/train/value_loss            | 0.887       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 548         |\n",
      "|    agent/time/iterations             | 74          |\n",
      "|    agent/time/time_elapsed           | 34          |\n",
      "|    agent/time/total_timesteps        | 18944       |\n",
      "|    agent/train/approx_kl             | 0.018879572 |\n",
      "|    agent/train/clip_fraction         | 0.212       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.441      |\n",
      "|    agent/train/explained_variance    | 0.911       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0289      |\n",
      "|    agent/train/n_updates             | 1460        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0293     |\n",
      "|    agent/train/value_loss            | 1.6         |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 75          |\n",
      "|    agent/time/time_elapsed           | 34          |\n",
      "|    agent/time/total_timesteps        | 19200       |\n",
      "|    agent/train/approx_kl             | 0.014835056 |\n",
      "|    agent/train/clip_fraction         | 0.301       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.484      |\n",
      "|    agent/train/explained_variance    | 0.959       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0987      |\n",
      "|    agent/train/n_updates             | 1480        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0372     |\n",
      "|    agent/train/value_loss            | 2.57        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 76          |\n",
      "|    agent/time/time_elapsed           | 35          |\n",
      "|    agent/time/total_timesteps        | 19456       |\n",
      "|    agent/train/approx_kl             | 0.022635726 |\n",
      "|    agent/train/clip_fraction         | 0.345       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.505      |\n",
      "|    agent/train/explained_variance    | 0.969       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0853      |\n",
      "|    agent/train/n_updates             | 1500        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0328     |\n",
      "|    agent/train/value_loss            | 2.4         |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 77          |\n",
      "|    agent/time/time_elapsed           | 35          |\n",
      "|    agent/time/total_timesteps        | 19712       |\n",
      "|    agent/train/approx_kl             | 0.014287832 |\n",
      "|    agent/train/clip_fraction         | 0.328       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.493      |\n",
      "|    agent/train/explained_variance    | 0.96        |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.044       |\n",
      "|    agent/train/n_updates             | 1520        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0361     |\n",
      "|    agent/train/value_loss            | 1.59        |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 20.5        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 78          |\n",
      "|    agent/time/time_elapsed           | 36          |\n",
      "|    agent/time/total_timesteps        | 19968       |\n",
      "|    agent/train/approx_kl             | 0.023617012 |\n",
      "|    agent/train/clip_fraction         | 0.284       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.447      |\n",
      "|    agent/train/explained_variance    | 0.961       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0331      |\n",
      "|    agent/train/n_updates             | 1540        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0253     |\n",
      "|    agent/train/value_loss            | 1.35        |\n",
      "------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -145       |\n",
      "|    agent/time/fps                    | 548        |\n",
      "|    agent/time/iterations             | 79         |\n",
      "|    agent/time/time_elapsed           | 36         |\n",
      "|    agent/time/total_timesteps        | 20224      |\n",
      "|    agent/train/approx_kl             | 0.00992387 |\n",
      "|    agent/train/clip_fraction         | 0.133      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.376     |\n",
      "|    agent/train/explained_variance    | 0.94       |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | 0.0413     |\n",
      "|    agent/train/n_updates             | 1560       |\n",
      "|    agent/train/policy_gradient_loss  | -0.0104    |\n",
      "|    agent/train/value_loss            | 0.959      |\n",
      "-----------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123       |\n",
      "|    agent/time/fps                    | 549        |\n",
      "|    agent/time/iterations             | 80         |\n",
      "|    agent/time/time_elapsed           | 37         |\n",
      "|    agent/time/total_timesteps        | 20480      |\n",
      "|    agent/train/approx_kl             | 0.02481395 |\n",
      "|    agent/train/clip_fraction         | 0.21       |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.38      |\n",
      "|    agent/train/explained_variance    | 0.998      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | -0.0467    |\n",
      "|    agent/train/n_updates             | 1580       |\n",
      "|    agent/train/policy_gradient_loss  | -0.0333    |\n",
      "|    agent/train/value_loss            | 0.232      |\n",
      "-----------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 548          |\n",
      "|    agent/time/iterations             | 81           |\n",
      "|    agent/time/time_elapsed           | 37           |\n",
      "|    agent/time/total_timesteps        | 20736        |\n",
      "|    agent/train/approx_kl             | 0.0054707015 |\n",
      "|    agent/train/clip_fraction         | 0.0213       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.191       |\n",
      "|    agent/train/explained_variance    | 0.926        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.134        |\n",
      "|    agent/train/n_updates             | 1600         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00123     |\n",
      "|    agent/train/value_loss            | 8.17         |\n",
      "-------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123       |\n",
      "|    agent/time/fps                    | 549        |\n",
      "|    agent/time/iterations             | 82         |\n",
      "|    agent/time/time_elapsed           | 38         |\n",
      "|    agent/time/total_timesteps        | 20992      |\n",
      "|    agent/train/approx_kl             | 0.08230379 |\n",
      "|    agent/train/clip_fraction         | 0.297      |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.418     |\n",
      "|    agent/train/explained_variance    | 0.668      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | -0.00884   |\n",
      "|    agent/train/n_updates             | 1620       |\n",
      "|    agent/train/policy_gradient_loss  | -0.0346    |\n",
      "|    agent/train/value_loss            | 0.384      |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 83          |\n",
      "|    agent/time/time_elapsed           | 38          |\n",
      "|    agent/time/total_timesteps        | 21248       |\n",
      "|    agent/train/approx_kl             | 0.025600217 |\n",
      "|    agent/train/clip_fraction         | 0.139       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.252      |\n",
      "|    agent/train/explained_variance    | 0.763       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.191       |\n",
      "|    agent/train/n_updates             | 1640        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0134     |\n",
      "|    agent/train/value_loss            | 2.35        |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 549          |\n",
      "|    agent/time/iterations             | 84           |\n",
      "|    agent/time/time_elapsed           | 39           |\n",
      "|    agent/time/total_timesteps        | 21504        |\n",
      "|    agent/train/approx_kl             | 0.0072385836 |\n",
      "|    agent/train/clip_fraction         | 0.0838       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.24        |\n",
      "|    agent/train/explained_variance    | 0.422        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0404       |\n",
      "|    agent/train/n_updates             | 1660         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00744     |\n",
      "|    agent/train/value_loss            | 1.04         |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 85          |\n",
      "|    agent/time/time_elapsed           | 39          |\n",
      "|    agent/time/total_timesteps        | 21760       |\n",
      "|    agent/train/approx_kl             | 0.009126949 |\n",
      "|    agent/train/clip_fraction         | 0.122       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.238      |\n",
      "|    agent/train/explained_variance    | 0.697       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0178      |\n",
      "|    agent/train/n_updates             | 1680        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0186     |\n",
      "|    agent/train/value_loss            | 0.784       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 86          |\n",
      "|    agent/time/time_elapsed           | 40          |\n",
      "|    agent/time/total_timesteps        | 22016       |\n",
      "|    agent/train/approx_kl             | 0.013967335 |\n",
      "|    agent/train/clip_fraction         | 0.11        |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.22       |\n",
      "|    agent/train/explained_variance    | 0.754       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | -0.00589    |\n",
      "|    agent/train/n_updates             | 1700        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0139     |\n",
      "|    agent/train/value_loss            | 0.366       |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 549          |\n",
      "|    agent/time/iterations             | 87           |\n",
      "|    agent/time/time_elapsed           | 40           |\n",
      "|    agent/time/total_timesteps        | 22272        |\n",
      "|    agent/train/approx_kl             | 0.0066816644 |\n",
      "|    agent/train/clip_fraction         | 0.116        |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.213       |\n",
      "|    agent/train/explained_variance    | 0.936        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | -0.00251     |\n",
      "|    agent/train/n_updates             | 1720         |\n",
      "|    agent/train/policy_gradient_loss  | -0.0131      |\n",
      "|    agent/train/value_loss            | 0.321        |\n",
      "-------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 88          |\n",
      "|    agent/time/time_elapsed           | 41          |\n",
      "|    agent/time/total_timesteps        | 22528       |\n",
      "|    agent/train/approx_kl             | 0.008522879 |\n",
      "|    agent/train/clip_fraction         | 0.0813      |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.191      |\n",
      "|    agent/train/explained_variance    | 0.939       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0218      |\n",
      "|    agent/train/n_updates             | 1740        |\n",
      "|    agent/train/policy_gradient_loss  | -0.00924    |\n",
      "|    agent/train/value_loss            | 0.533       |\n",
      "------------------------------------------------------\n",
      "-------------------------------------------------------\n",
      "| raw/                                 |              |\n",
      "|    agent/rollout/ep_len_mean         | 500          |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1         |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123         |\n",
      "|    agent/time/fps                    | 549          |\n",
      "|    agent/time/iterations             | 89           |\n",
      "|    agent/time/time_elapsed           | 41           |\n",
      "|    agent/time/total_timesteps        | 22784        |\n",
      "|    agent/train/approx_kl             | 0.0044080284 |\n",
      "|    agent/train/clip_fraction         | 0.0539       |\n",
      "|    agent/train/clip_range            | 0.2          |\n",
      "|    agent/train/entropy_loss          | -0.181       |\n",
      "|    agent/train/explained_variance    | 0.891        |\n",
      "|    agent/train/learning_rate         | 0.001        |\n",
      "|    agent/train/loss                  | 0.0293       |\n",
      "|    agent/train/n_updates             | 1760         |\n",
      "|    agent/train/policy_gradient_loss  | -0.00621     |\n",
      "|    agent/train/value_loss            | 0.756        |\n",
      "-------------------------------------------------------\n",
      "-----------------------------------------------------\n",
      "| raw/                                 |            |\n",
      "|    agent/rollout/ep_len_mean         | 500        |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1       |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123       |\n",
      "|    agent/time/fps                    | 549        |\n",
      "|    agent/time/iterations             | 90         |\n",
      "|    agent/time/time_elapsed           | 41         |\n",
      "|    agent/time/total_timesteps        | 23040      |\n",
      "|    agent/train/approx_kl             | 0.01759378 |\n",
      "|    agent/train/clip_fraction         | 0.0637     |\n",
      "|    agent/train/clip_range            | 0.2        |\n",
      "|    agent/train/entropy_loss          | -0.168     |\n",
      "|    agent/train/explained_variance    | 0.938      |\n",
      "|    agent/train/learning_rate         | 0.001      |\n",
      "|    agent/train/loss                  | 0.0342     |\n",
      "|    agent/train/n_updates             | 1780       |\n",
      "|    agent/train/policy_gradient_loss  | -0.00709   |\n",
      "|    agent/train/value_loss            | 0.899      |\n",
      "-----------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 91          |\n",
      "|    agent/time/time_elapsed           | 42          |\n",
      "|    agent/time/total_timesteps        | 23296       |\n",
      "|    agent/train/approx_kl             | 0.016167853 |\n",
      "|    agent/train/clip_fraction         | 0.116       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.183      |\n",
      "|    agent/train/explained_variance    | 0.93        |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.00466     |\n",
      "|    agent/train/n_updates             | 1800        |\n",
      "|    agent/train/policy_gradient_loss  | -0.0147     |\n",
      "|    agent/train/value_loss            | 0.873       |\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------\n",
      "| raw/                                 |             |\n",
      "|    agent/rollout/ep_len_mean         | 500         |\n",
      "|    agent/rollout/ep_rew_mean         | 19.1        |\n",
      "|    agent/rollout/ep_rew_wrapped_mean | -123        |\n",
      "|    agent/time/fps                    | 549         |\n",
      "|    agent/time/iterations             | 92          |\n",
      "|    agent/time/time_elapsed           | 42          |\n",
      "|    agent/time/total_timesteps        | 23552       |\n",
      "|    agent/train/approx_kl             | 0.006916553 |\n",
      "|    agent/train/clip_fraction         | 0.099       |\n",
      "|    agent/train/clip_range            | 0.2         |\n",
      "|    agent/train/entropy_loss          | -0.196      |\n",
      "|    agent/train/explained_variance    | 0.884       |\n",
      "|    agent/train/learning_rate         | 0.001       |\n",
      "|    agent/train/loss                  | 0.0702      |\n",
      "|    agent/train/n_updates             | 1820        |\n",
      "|    agent/train/policy_gradient_loss  | -0.00954    |\n",
      "|    agent/train/value_loss            | 0.841       |\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c2f6ca05d550c2e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
